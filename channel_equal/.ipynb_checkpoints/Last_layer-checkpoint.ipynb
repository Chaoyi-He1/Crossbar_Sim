{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c732b887-5a0a-4abc-ac43-b03dbfc234b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import scipy.io as sio\n",
    "from collections import defaultdict, deque\n",
    "import datetime\n",
    "import time\n",
    "import torch.distributed as dist\n",
    "import errno\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef1a693-720d-4def-8f40-51b4dee6cd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothedValue(object):\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{value:.4f} ({global_avg:.4f})\"\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.total = t[1]\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return max(self.deque)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.deque[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value)\n",
    "\n",
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, attr))\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\n",
    "                \"{}: {}\".format(name, str(meter))\n",
    "            )\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = ''\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
    "        if torch.cuda.is_available():\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}',\n",
    "                'max mem: {memory:.0f}'\n",
    "            ])\n",
    "        else:\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}'\n",
    "            ])\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                if torch.cuda.is_available():\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
    "                else:\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time)))\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('{} Total time: {}'.format(header, total_time_str))\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6807efb-a5bb-4256-8064-79e07dfe9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "class channel_dataset_last_layer(data.Dataset):\n",
    "    def __init__(self, data_path, use_noise: bool = False, is_train: bool = True):\n",
    "        super(channel_dataset_last_layer, self).__init__()\n",
    "        self.data_path = data_path\n",
    "        self.data = sio.loadmat(data_path)\n",
    "        self.use_noise = use_noise\n",
    "        self.is_train = is_train\n",
    "        self.HW_data = np.load(data_path.replace(\"channel_equal_train.mat\", \"mlp_layer_1_out_all.npy\")) if self.is_train else np.load(data_path.replace(\"channel_equal_val.mat\", \"mlp_layer_1_out_all.npy\"))\n",
    "\n",
    "        self.trans = transform_data()\n",
    "\n",
    "        self.tx_data = self.data['Xt_train'] if self.is_train else self.data['Xt_val']\n",
    "        self.rx_data = self.data['rx_Xt_train'] if self.is_train else self.data['rx_Xt_val']\n",
    "        self.rx_data_noised = self.data['rx_Xt_noise_train'] if self.is_train else self.data['rx_Xt_noise_val']\n",
    "\n",
    "        self.tx_data = self.tx_data.astype(np.float32)\n",
    "        self.rx_data = self.rx_data.astype(np.float32)\n",
    "        self.rx_data_noised = self.rx_data_noised.astype(np.float32)\n",
    "\n",
    "        # use min-max normalize to rescale the data to int val of [10, 240]\n",
    "        self.tx_data = (self.tx_data - np.min(self.tx_data)) / (np.max(self.tx_data) - np.min(self.tx_data)) * 230 + 10\n",
    "        self.rx_data = (self.rx_data - np.min(self.rx_data)) / (np.max(self.rx_data) - np.min(self.rx_data)) * 230 + 10\n",
    "        self.rx_data_noised = (self.rx_data_noised - np.min(self.rx_data_noised)) / (np.max(self.rx_data_noised) - np.min(self.rx_data_noised)) * 230 + 10\n",
    "        self.HW_data = (self.HW_data / 255).reshape(-1, 1, 1, 128)\n",
    "        \n",
    "        self.tx_data = self.tx_data.astype(np.uint8)\n",
    "        self.rx_data = self.rx_data.astype(np.uint8)\n",
    "        self.rx_data_noised = self.rx_data_noised.astype(np.uint8)\n",
    "\n",
    "        # transfer the tx_data's each element into 7-bits binary digits, as the range is in [0, 128]\n",
    "        self.tx_data_label = np.unpackbits(self.tx_data, axis=-1)\n",
    "        self.tx_data_label = self.tx_data_label.reshape(*self.tx_data.shape, -1)\n",
    "        self.tx_data_label = self.tx_data_label[:, :, 0:].reshape(-1, 64 * 8).astype(float)\n",
    "\n",
    "        self.tx_pilot, self.tx_data = self.tx_data[:64], self.tx_data[64:].reshape(-1, 8, 8, 1)\n",
    "        self.rx_pilot, self.rx_data = self.rx_data[:64], self.rx_data[64:].reshape(-1, 8, 8, 1)\n",
    "        self.rx_pilot_noised, self.rx_data_noised = self.rx_data_noised[:64], self.rx_data_noised[64:].reshape(-1, 8, 8, 1)\n",
    "        self.tx_data_label_pilot, self.tx_data_label = self.tx_data_label[:64], self.tx_data_label[64:]\n",
    "\n",
    "        self.tx_pilot = self.tx_pilot[:, :, None]\n",
    "        self.rx_pilot, self.rx_pilot_noised = self.rx_pilot[:, :, None], self.rx_pilot_noised[:, :, None]\n",
    "\n",
    "        self.HW_data = self.HW_data[:self.rx_data.shape[0]] if self.is_train else self.HW_data[-self.rx_data.shape[0]:]\n",
    "\n",
    "        self.num_samples = self.tx_data.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __get_pilot__(self):\n",
    "        if self.use_noise:\n",
    "            return self.trans(self.tx_pilot).unsqueeze(0), self.trans(self.rx_pilot_noised).unsqueeze(0)\n",
    "        else:\n",
    "            return self.trans(self.tx_pilot).unsqueeze(0), self.trans(self.rx_pilot).unsqueeze(0)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.use_noise:\n",
    "            # return self.trans(self.tx_data[index]).view(-1), self.trans(self.HW_data[index]).view(-1)\n",
    "            return torch.tensor(self.tx_data_label[index]), torch.tensor(self.HW_data[index]).view(-1)\n",
    "        else:\n",
    "            # return self.trans(self.tx_data[index]).view(-1), self.trans(self.rx_data[index])\n",
    "            return torch.tensor(self.tx_data_label[index]), self.trans(self.rx_data[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b253eb4-91d0-4bd1-a953-0131599277e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Equalizer_last_layer(nn.Module):\n",
    "    def __init__(self, input_size: int = 64, latent_size: int = 64):\n",
    "        super(Equalizer_last_layer, self).__init__()\n",
    "        self.equalizer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, input_size * 8),\n",
    "        )\n",
    "\n",
    "    def forward(self, rx_input):\n",
    "        equalized_output = rx_input\n",
    "        equalized_output = self.equalizer(equalized_output)\n",
    "        return equalized_output\n",
    "\n",
    "# saperate the last layer into 16 subblocks\n",
    "class Equalizer_HW_split(nn.Module):\n",
    "    def __init__(self, input_size: int = 64, latent_size: int = 64):\n",
    "        super(Equalizer_HW_split, self).__init__()\n",
    "        self.equalizer = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, input_size * 8 // 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, rx_input):\n",
    "        equalized_output = rx_input\n",
    "        equalized_output = self.equalizer(equalized_output)\n",
    "        return equalized_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3e7899-d0c3-4d3f-b5d1-460e08195c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_regularize(model, device, alpha=0.2):\n",
    "    central_params = torch.arange(0.0, 1.1, 0.1).to(device)\n",
    "    reg_params = {}\n",
    "    for c in central_params:\n",
    "        if c == 0.0:\n",
    "            reg_params[c] = [p.abs() < 0.05 for n, p in model.named_parameters()]\n",
    "        if c == 1.0:\n",
    "            reg_params[c] = [p.abs() > 0.95 for n, p in model.named_parameters()]\n",
    "        else:\n",
    "            reg_params[c] = [(c - 0.05 <= p.abs()) & (p.abs() < c + 0.05) for n, p in model.named_parameters()]\n",
    "\n",
    "    reg_loss = 0.0\n",
    "    for c, params in reg_params.items():\n",
    "        reg_loss += alpha * torch.sum(torch.stack([torch.sum((p[params[i]].abs() - c).abs()) for i, (n, p) in enumerate(model.named_parameters())]))\n",
    "\n",
    "    return reg_loss\n",
    "\n",
    "# extract compressed feature\n",
    "def get_first_layer_output(model, input_tensor):\n",
    "    first_layer_output = None\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        nonlocal first_layer_output\n",
    "        first_layer_output = output\n",
    "\n",
    "    # Register hook on the first Linear layer\n",
    "    hook = model.equalizer[2].register_forward_hook(hook_fn)\n",
    "\n",
    "    # Forward pass\n",
    "    model(input_tensor)\n",
    "\n",
    "    # Remove the hook\n",
    "    hook.remove()\n",
    "\n",
    "    # Return the captured output\n",
    "    return first_layer_output\n",
    "\n",
    "# train one epoch\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq, scaler):\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"    \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    # take pilots\n",
    "    tx_pilot, rx_pilot = data_loader.dataset.__get_pilot__()\n",
    "    tx_pilot, rx_pilot = tx_pilot.to(device), rx_pilot.to(device)\n",
    "\n",
    "    # expand pilots among the batch_size dim\n",
    "    tx_pilot = tx_pilot.expand(data_loader.batch_size, -1, -1, -1)\n",
    "    rx_pilot = rx_pilot.expand(data_loader.batch_size, -1, -1, -1)\n",
    "\n",
    "    for tx_input, rx_input in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        tx_input, rx_input = tx_input.to(device), rx_input.to(device).to(torch.float)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            # equalized_output = model(tx_pilot, rx_pilot, rx_input)\n",
    "            equalized_output = model(rx_input)\n",
    "            loss = F.binary_cross_entropy_with_logits(equalized_output, tx_input)\n",
    "\n",
    "            if epoch >= 10:\n",
    "                loss += quantize_regularize(model, device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        metric_logger.update(loss=loss, lr=optimizer.param_groups[0][\"lr\"])\n",
    "        # calculate binary accuracy\n",
    "        output_bits = (equalized_output > 0).to(torch.uint8)\n",
    "        accuracy = (output_bits == tx_input.to(torch.uint8)).float().mean()\n",
    "        metric_logger.update(accuracy=accuracy)\n",
    "\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n",
    "def evaluate(model, data_loader, device, epoch, print_freq):\n",
    "    model.eval()\n",
    "    metric_logger = MetricLogger(delimiter=\"    \")\n",
    "    header = 'Test: Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    tx_pilot, rx_pilot = data_loader.dataset.__get_pilot__()\n",
    "    tx_pilot, rx_pilot = tx_pilot.to(device), rx_pilot.to(device)\n",
    "\n",
    "    tx_pilot = tx_pilot.expand(data_loader.batch_size, -1, -1, -1)\n",
    "    rx_pilot = rx_pilot.expand(data_loader.batch_size, -1, -1, -1)\n",
    "    tx_pilot.requires_grad = False\n",
    "    rx_pilot.requires_grad = False\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            for tx_input, rx_input in metric_logger.log_every(data_loader, print_freq, header):\n",
    "                tx_input, rx_input = tx_input.to(device), rx_input.to(device).to(torch.float)\n",
    "\n",
    "                # equalized_output = model(tx_pilot, rx_pilot, rx_input)\n",
    "                equalized_output = model(rx_input)\n",
    "                loss = F.binary_cross_entropy_with_logits(equalized_output, tx_input)\n",
    "\n",
    "                metric_logger.update(loss=loss)\n",
    "                # calculate binary accuracy\n",
    "                output_bits = (equalized_output > 0).to(torch.uint8)\n",
    "                accuracy = (output_bits == tx_input.to(torch.uint8)).float().mean()\n",
    "                metric_logger.update(accuracy=accuracy)\n",
    "\n",
    "    metric_logger.synchronize_between_processes()\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75c61366-6507-4e4f-aa7a-85054b0e5b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(snr):\n",
    "    # set seed\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    batch_size = 256\n",
    "    num_epoch = 300\n",
    "    lr = 0.01\n",
    "    lrf = 0.1\n",
    "\n",
    "    train_data_path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/shuffle/channel_equal_train.mat\"\n",
    "    val_data_path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/shuffle/channel_equal_val.mat\"\n",
    "\n",
    "    train_dataset = channel_dataset_after_CNN(train_data_path, use_noise=True, is_train=True)\n",
    "    val_dataset = channel_dataset_after_CNN(val_data_path, use_noise=True, is_train=False)\n",
    "\n",
    "    train_sampler = data.RandomSampler(train_dataset)\n",
    "    val_sampler = data.SequentialSampler(val_dataset)\n",
    "\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # model = Equalizer().to(device)\n",
    "    model = Equalizer_HW_after_CNN().to(device)\n",
    "\n",
    "    params_to_optimize = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / num_epoch)) / 2) * (1 - lrf) + lrf\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    scheduler.last_epoch = 0\n",
    "\n",
    "    best_loss, best_epoch = math.inf, 0\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epoch):\n",
    "        train_dict = train_one_epoch(model, optimizer, train_loader, device, epoch, print_freq=10, scaler=scaler)\n",
    "        val_dict = evaluate(model, val_loader, device, epoch, print_freq=5)\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch >= 10 and val_dict['loss'] < best_loss:\n",
    "            best_loss = val_dict['loss']\n",
    "            best_epoch = epoch\n",
    "            save_file = {\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "                \"epoch\": epoch\n",
    "            }\n",
    "            torch.save(save_file, \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/best_model.pth\")\n",
    "            print(\"Save model from: \", epoch)\n",
    "\n",
    "    print(\"Total time: {}s\".format(int(time.time() - start_time)))\n",
    "    print(\"Best loss: {}\".format(best_loss), \";  Best Epoch: {}\".format(best_epoch))\n",
    "\n",
    "    # min, max of the model parameters\n",
    "    min_params, max_params = [], []\n",
    "    for p in model.parameters():\n",
    "        min_params.append(p.min().item())\n",
    "        max_params.append(p.max().item())\n",
    "    min_params, max_params = np.min(min_params), np.max(max_params)\n",
    "    print(f\"Min of model parameters: {min_params}, Max of model parameters: {max_params}\")\n",
    "    # plot histogram of model parameters\n",
    "    params = [p.detach().cpu().numpy().flatten() for p in model.parameters()]\n",
    "    plt.hist(np.hstack(params), bins=100)\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2238443-b7e8-4642-9379-2ac1cfdc14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430126a4-b581-4c39-a8dc-568627973385",
   "metadata": {},
   "outputs": [],
   "source": [
    "main(snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2df14c-5ab8-4ba4-917d-9db93a73310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize a input vector randomly from the dataset, plot the rx, tx and the output equalized rx from model\n",
    "def visualize_output(model, data_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    random_index = random.randint(0, len(data_loader.dataset) - 1)\n",
    "    tx_input, rx_input = data_loader.dataset[random_index]\n",
    "    tx_input, rx_input = tx_input.to(device).unsqueeze(0), rx_input.to(device).unsqueeze(0).to(torch.float)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            equalized_output = model(rx_input).sigmoid().round()\n",
    "            loss = F.mse_loss(equalized_output, tx_input)\n",
    "    equalized_output = equalized_output.view(-1, 64, 8)\n",
    "    tx_input = tx_input.view(-1, 64, 8)\n",
    "    \n",
    "    equalized_output = torch.sum(equalized_output * (2 ** torch.arange(7, -1, -1, device=device).float()), dim=-1).to(torch.uint8)\n",
    "    tx_input = torch.sum(tx_input * (2 ** torch.arange(7, -1, -1, device=device).float()), dim=-1).to(torch.uint8)\n",
    "\n",
    "    tx_input = tx_input.cpu().numpy()\n",
    "    equalized_output = equalized_output.cpu().numpy()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(tx_input[0], label='tx')\n",
    "    plt.plot(equalized_output[0], label='calibrated')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def save_compress_data(model, data_loader, device, snr, tx_input, is_train):\n",
    "    model.eval()\n",
    "    compress_data = []\n",
    "    tx_labels = []\n",
    "    for tx_label, HW_data in data_loader:\n",
    "        HW_data = HW_data.to(device).to(torch.float)\n",
    "        with torch.no_grad():\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                res = get_first_layer_output(model, HW_data)\n",
    "                compress_data.append(res.cpu().numpy())\n",
    "                tx_labels.append(tx_label.cpu().numpy())\n",
    "    tx_input_label, rx_input = np.vstack(tx_labels), np.vstack(compress_data)\n",
    "    path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/train_rx_input_compresses.npz\" if is_train else \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/val_rx_input_compresses.npz\"\n",
    "    np.savez(path, rx_input=rx_input, tx_input=tx_input, tx_input_label=tx_input_label)\n",
    "\n",
    "# the function to call this visual function\n",
    "def test(snr):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch_size = 1\n",
    "    \n",
    "    val_data_path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/shuffle/channel_equal_val.mat\"\n",
    "    val_dataset = channel_dataset_after_CNN(val_data_path, use_noise=True, is_train=False)\n",
    "    val_sampler = data.SequentialSampler(val_dataset)\n",
    "    val_loader = data.DataLoader(val_dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True)\n",
    "\n",
    "    train_data_path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/shuffle/channel_equal_train.mat\"\n",
    "    train_dataset = channel_dataset_after_CNN(train_data_path, use_noise=True, is_train=True)\n",
    "    train_sampler = data.SequentialSampler(train_dataset)\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "    \n",
    "    model = Equalizer_HW_after_CNN().to(device)\n",
    "    # model_c = Equalizer_HW_after_CNN().to(device)\n",
    "\n",
    "    model_path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/best_model.pth\"\n",
    "    ckpt = torch.load(model_path)['model']\n",
    "    # model_c.load_state_dict(ckpt)\n",
    "    # model_c.eval()\n",
    "    \n",
    "    # new_state_dict = {}\n",
    "    # for k, v in ckpt.items():\n",
    "    #     print(k)\n",
    "    #     if \"equalizer.1\" in k:\n",
    "    #         continue\n",
    "    #     elif \"equalizer.3\" in k:\n",
    "    #         new_key = k.replace(\"equalizer.3\", \"equalizer.1\")\n",
    "    #     elif \"equalizer.5\" in k:\n",
    "    #         new_key = k.replace(\"equalizer.5\", \"equalizer.3\")\n",
    "    #     new_state_dict[new_key] = v\n",
    "        \n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    visualize_output(model, val_loader, device)\n",
    "    # save_compress_data(model_c, train_loader, device, snr, train_dataset.tx_data, True)\n",
    "    # save_compress_data(model_c, val_loader, device, snr, val_dataset.tx_data, False)\n",
    "    \n",
    "    model_HW_splits = [Equalizer_HW_split().to(device) for _ in range(16)]\n",
    "    \n",
    "    # Ensure the last layer exists and has the correct shape\n",
    "    last_layer = list(model.equalizer.children())[-1]\n",
    "    assert isinstance(last_layer, nn.Linear), \"Expected the last layer to be Linear\"\n",
    "    assert last_layer.weight.data.shape[0] % 16 == 0, \"Output size not divisible by 16\"\n",
    "    \n",
    "    for i in range(16):\n",
    "        # Assign only the last layer's weights and biases to each split model\n",
    "        model_HW_splits[i].equalizer[-1].weight.data = last_layer.weight.data[i * 32: (i + 1) * 32, :].clone()\n",
    "        model_HW_splits[i].equalizer[-1].bias.data = last_layer.bias.data[i * 32: (i + 1) * 32].clone()\n",
    "    \n",
    "        # If additional layers need loading, do so selectively\n",
    "        for j, (split_layer, model_layer) in enumerate(zip(model_HW_splits[i].equalizer.children(), model.equalizer.children())):\n",
    "            if j != len(model.equalizer) - 1:  # Skip the last layer\n",
    "                split_layer.load_state_dict(model_layer.state_dict())\n",
    "\n",
    "\n",
    "    # min, max of the model parameters\n",
    "    min_params, max_params = [], []\n",
    "    for p in model.parameters():\n",
    "        min_params.append(p.min().item())\n",
    "        max_params.append(p.max().item())\n",
    "    min_params, max_params = np.min(min_params), np.max(max_params)\n",
    "    print(f\"Min of model parameters: {min_params}, Max of model parameters: {max_params}\")\n",
    "    # plot histogram of model parameters\n",
    "    params = [p.detach().cpu().numpy().flatten() for p in model.parameters()]\n",
    "    # plt.figure(figsize=(10, 5))\n",
    "    # plt.hist(np.hstack(params), bins=100)\n",
    "    # plt.show()\n",
    "\n",
    "    dummy_input = torch.randn(1, 1, 1, 128).to(device)\n",
    "    torch.onnx.export(model, dummy_input,\n",
    "                      \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/model_after_CNN.onnx\",\n",
    "                      export_params=True, opset_version=16, dynamic_axes={'input': {0: 'batch_size'}, 'sensor_out': {0: 'batch_size'}},\n",
    "                      input_names=['input'], output_names=['sensor_out'])\n",
    "\n",
    "    for i in range(16):\n",
    "        path = \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/split_model_no_CNN/\"\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        torch.onnx.export(model_HW_splits[i], dummy_input,\n",
    "                          \"./channel_Rayleigh/\" + str(snr) + \"/PSK16/split_model_no_CNN/best_model_HW_{}.onnx\".format(i),\n",
    "                          export_params=True, opset_version=16, dynamic_axes={'input': {0: 'batch_size'}, 'sensor_out': {0: 'batch_size'}},\n",
    "                          input_names=['input'], output_names=['sensor_out'])\n",
    "    return model\n",
    "\n",
    "model = test(snr)\n",
    "for p in model.parameters():\n",
    "    print(p.mean(), p.std())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
