{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fj-e25bL9qsl",
    "outputId": "21d773c2-ce4d-4732-aec6-b554f95b0ae4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "import h5py\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import random_split\n",
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Optional, Tuple, List, Iterable\n",
    "from torch import nn, Tensor\n",
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, Tensor\n",
    "import sys\n",
    "import torch.distributed as dist\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import subprocess\n",
    "import time\n",
    "from collections import defaultdict, deque\n",
    "import datetime\n",
    "import pickle\n",
    "from contextlib import contextmanager\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IPqo3maC-Cwn"
   },
   "outputs": [],
   "source": [
    "def is_dist_avail_and_initialized():\n",
    "    if not dist.is_available():\n",
    "        return False\n",
    "    if not dist.is_initialized():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "class SmoothedValue(object):\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value, n=1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"\n",
    "        Warning: does not synchronize the deque!\n",
    "        \"\"\"\n",
    "        if not is_dist_avail_and_initialized():\n",
    "            return\n",
    "        t = torch.tensor([self.count, self.total], dtype=torch.float64, device='cuda')\n",
    "        dist.barrier()\n",
    "        dist.all_reduce(t)\n",
    "        t = t.tolist()\n",
    "        self.count = int(t[0])\n",
    "        self.total = t[1]\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return max(self.deque)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.deque[-1]\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value)\n",
    "\n",
    "\n",
    "class MetricLogger(object):\n",
    "    def __init__(self, delimiter=\"\\t\"):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            assert isinstance(v, (float, int))\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n",
    "            type(self).__name__, attr))\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(\n",
    "                \"{}: {}\".format(name, str(meter))\n",
    "            )\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None):\n",
    "        i = 0\n",
    "        if not header:\n",
    "            header = ''\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        data_time = SmoothedValue(fmt='{avg:.4f}')\n",
    "        space_fmt = ':' + str(len(str(len(iterable)))) + 'd'\n",
    "        if torch.cuda.is_available():\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}',\n",
    "                'max mem: {memory:.0f}'\n",
    "            ])\n",
    "        else:\n",
    "            log_msg = self.delimiter.join([\n",
    "                header,\n",
    "                '[{0' + space_fmt + '}/{1}]',\n",
    "                'eta: {eta}',\n",
    "                '{meters}',\n",
    "                'time: {time}',\n",
    "                'data: {data}'\n",
    "            ])\n",
    "        MB = 1024.0 * 1024.0\n",
    "        for obj in iterable:\n",
    "            data_time.update(time.time() - end)\n",
    "            yield obj\n",
    "            iter_time.update(time.time() - end)\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                eta_seconds = iter_time.global_avg * (len(iterable) - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                if torch.cuda.is_available():\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time),\n",
    "                        memory=torch.cuda.max_memory_allocated() / MB))\n",
    "                else:\n",
    "                    print(log_msg.format(\n",
    "                        i, len(iterable), eta=eta_string,\n",
    "                        meters=str(self),\n",
    "                        time=str(iter_time), data=str(data_time)))\n",
    "            i += 1\n",
    "            end = time.time()\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print('{} Total time: {} ({:.4f} s / it)'.format(\n",
    "            header, total_time_str, total_time / len(iterable)))\n",
    "\n",
    "\n",
    "class Step_Prediction(object):\n",
    "    def __init__(self, num_steps: int = 12) -> None:\n",
    "        self.num_steps = num_steps\n",
    "        self.acc_vec = np.zeros(num_steps)\n",
    "        self.update_count = 0\n",
    "\n",
    "    def update(self, steps_acc):\n",
    "        for i, acc in enumerate(steps_acc):\n",
    "            if isinstance(acc, torch.Tensor):\n",
    "                acc = acc.item()\n",
    "            self.acc_vec[i] += acc\n",
    "        self.update_count += 1\n",
    "\n",
    "    def reset(self):\n",
    "        self.acc_vec = np.zeros(self.num_steps)\n",
    "\n",
    "    def compute(self):\n",
    "        return self.acc_vec / self.update_count\n",
    "\n",
    "    def reduce_from_all_processes(self):\n",
    "        if not torch.distributed.is_available():\n",
    "            return\n",
    "        if not torch.distributed.is_initialized():\n",
    "            return\n",
    "        torch.distributed.barrier()\n",
    "        torch.distributed.all_reduce(self.acc_vec)\n",
    "\n",
    "    def __str__(self):\n",
    "        steps_acc = self.compute()\n",
    "        return \" \".join([f\"step_{i}: {acc:.4f}\" for i, acc in enumerate(steps_acc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "rDt55MgA9v35"
   },
   "outputs": [],
   "source": [
    "class XB_dataset_npy(Dataset):\n",
    "    def __init__(self, out_I_paths, ideal_out_I_paths, mtx_paths, float_mtx_path) -> None:\n",
    "        super().__init__()\n",
    "        self.ideal_out_I_path = ideal_out_I_paths\n",
    "        self.out_I_path = out_I_paths\n",
    "        self.mtx_path = mtx_paths\n",
    "        self.float_mtx_path = float_mtx_path\n",
    "        self.cache_data()\n",
    "        self.num_in = self.out_I.shape[0]\n",
    "        # print(self.Weight_mtx.shape[0], self.num_in)\n",
    "\n",
    "    def cache_data(self):\n",
    "        num_rows = [np.load(file).shape[0] for file in self.out_I_path]\n",
    "        self.out_I = np.vstack([np.load(file) for file in self.out_I_path])\n",
    "        self.ideal_out_I = np.vstack([np.load(file) for file in self.ideal_out_I_path])\n",
    "        self.Weight_mtx = np.vstack([np.tile(np.load(file), (num_rows[i], 1, 1)) for i, file in enumerate(self.mtx_path)])\n",
    "        self.float_weight_mtx = np.load(self.float_mtx_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_in\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        Matrix = np.stack([self.Weight_mtx[index], self.float_weight_mtx], 0)\n",
    "        Iout = self.out_I[index]\n",
    "        ideal_Iout = self.ideal_out_I[index]\n",
    "        return Matrix, Iout, ideal_Iout\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        Matrix, Iout, ideal_Iout = list(zip(*batch))\n",
    "        Matrix = torch.from_numpy(np.stack(Matrix, 0)).float()\n",
    "        Iout = torch.from_numpy(np.stack(Iout, 0)).float()\n",
    "        ideal_Iout = torch.from_numpy(np.stack(ideal_Iout, 0)).long()\n",
    "        return Matrix, Iout, ideal_Iout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "c_aS0VS0-ADz"
   },
   "outputs": [],
   "source": [
    "class ConcatSquashLinear(nn.Module):\n",
    "    def __init__(self, dim_in, dim_out, dim_ctx):\n",
    "        super(ConcatSquashLinear, self).__init__()\n",
    "        self._layer = nn.Linear(dim_in, dim_out)\n",
    "        self._hyper_bias = nn.Linear(dim_ctx, dim_out, bias=False)\n",
    "        self._hyper_gate = nn.Linear(dim_ctx, dim_out)\n",
    "\n",
    "    def forward(self, ctx, x):\n",
    "        gate = torch.sigmoid(self._hyper_gate(ctx))\n",
    "        bias = self._hyper_bias(ctx)\n",
    "        # if x.dim() == 3:\n",
    "        #     gate = gate.unsqueeze(1)\n",
    "        #     bias = bias.unsqueeze(1)\n",
    "        ret = self._layer(x) * gate + bias\n",
    "        return ret\n",
    "\n",
    "\n",
    "class Calib_model(nn.Module):\n",
    "    def __init__(self, ctx_dim, out_type) -> None:\n",
    "        super().__init__()\n",
    "        self.ctx_dim = ctx_dim\n",
    "        self.conv = nn.Conv2d(in_channels=2, out_channels=ctx_dim,\n",
    "                              kernel_size=(16, 32))\n",
    "        self.MLP = nn.ModuleList([\n",
    "            ConcatSquashLinear(32, 128, ctx_dim)\n",
    "        ])\n",
    "        self.MLP.extend([\n",
    "            ConcatSquashLinear(128, 128, ctx_dim)\n",
    "        ] * 4)\n",
    "        self.cls_head = nn.ModuleList([ConcatSquashLinear(128, 256, ctx_dim)] * 32) if out_type == \"cls\" else \\\n",
    "                        ConcatSquashLinear(128, 32, ctx_dim)\n",
    "        self.out_type = out_type\n",
    "\n",
    "    def forward(self, mtx, exp_Iout):\n",
    "        ctx = self.conv(mtx).squeeze()\n",
    "        ideal_Iout = exp_Iout\n",
    "        for layer in self.MLP:\n",
    "            ideal_Iout = layer(ctx, ideal_Iout)\n",
    "        pred = torch.stack([layer(ctx, ideal_Iout) for layer in self.cls_head], dim=1).to(mtx.device) if self.out_type == \"cls\" else \\\n",
    "                self.cls_head(ctx, ideal_Iout)\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YywaxEKuG4s5"
   },
   "outputs": [],
   "source": [
    "def accuracy_cal(pred, target):\n",
    "    pred_cls = torch.argmax(pred, dim=-1) if len(pred.shape) == 3 else \\\n",
    "               torch.round(pred).long()\n",
    "    # Calculate correct predictions\n",
    "    correct_predictions = (pred_cls == target)\n",
    "    # Calculate accuracy for each batch\n",
    "    accuracies = correct_predictions.float().mean(dim=1)\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def train_one_epoch(model: torch.nn.Module, data_loader: Iterable,\n",
    "                    optimizer: torch.optim.Optimizer, out_type: str,\n",
    "                    device: torch.device, epoch: int, max_norm: float = 0.1,\n",
    "                    ):\n",
    "    model.train()\n",
    "    metric_logger = MetricLogger(delimiter=\"; \")\n",
    "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('loss', SmoothedValue(window_size=10, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('accuracy', SmoothedValue(window_size=10, fmt='{value:.6f}'))\n",
    "    batch_Predict = Step_Prediction(num_steps=32)\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    for i, (Matrix, Iout, ideal_Iout) in enumerate(metric_logger.log_every(data_loader, 100, header)):\n",
    "        Matrix = Matrix.to(device)\n",
    "        Iout = Iout.to(device)\n",
    "        ideal_Iout = ideal_Iout.to(device)\n",
    "\n",
    "        I_pred = model(Matrix, Iout)\n",
    "        loss = F.cross_entropy(I_pred.transpose(1, 2), ideal_Iout) if out_type == 'cls' else \\\n",
    "               F.mse_loss(I_pred, ideal_Iout)\n",
    "        acc = accuracy_cal(I_pred, ideal_Iout)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(accuracy=acc.mean().item())\n",
    "        batch_Predict.update(acc)\n",
    "\n",
    "    print(\"Averaged stats:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}, batch_Predict\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluation(model: torch.nn.Module, data_loader: Iterable,\n",
    "               out_type: str, device: torch.device, epoch: int,\n",
    "               ):\n",
    "    model.eval()\n",
    "    metric_logger = MetricLogger(delimiter=\"; \")\n",
    "    metric_logger.add_meter('loss', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    metric_logger.add_meter('accuracy', SmoothedValue(window_size=10, fmt='{value:.6f}'))\n",
    "    batch_Predict = Step_Prediction(num_steps=32)\n",
    "    header = 'Test:'\n",
    "\n",
    "    for i, (Matrix, Iout, ideal_Iout) in enumerate(metric_logger.log_every(data_loader, 100, header)):\n",
    "        Matrix = Matrix.to(device)\n",
    "        Iout = Iout.to(device)\n",
    "        ideal_Iout = ideal_Iout.to(device)\n",
    "\n",
    "        I_pred = model(Matrix, Iout)\n",
    "        loss = F.cross_entropy(I_pred.transpose(1, 2), ideal_Iout) if out_type == 'cls' else \\\n",
    "               F.mse_loss(I_pred, ideal_Iout)\n",
    "        acc = accuracy_cal(I_pred, ideal_Iout)\n",
    "\n",
    "        metric_logger.update(loss=loss.item())\n",
    "        metric_logger.update(accuracy=acc.mean().item())\n",
    "        batch_Predict.update(acc)\n",
    "\n",
    "    print(\"Averaged stats metric logger:\", metric_logger)\n",
    "    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}, batch_Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "95X0HN-1KABA"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    float_mtx_path = '../data/Calib/uniform_weight.npy'\n",
    "    mtx_path = ['../data/Calib/qtz_mtx_xb_uniform.npy',\n",
    "                '../data/Calib/qtz_mtx_xb_uniform_bit_norm.npy',\n",
    "                '../data/Calib/qtz_mtx_xb_uniform_mid_g.npy']\n",
    "    ideal_out_I_path = ['../data/Calib/ideal_out_xb_uniform.npy',\n",
    "                        '../data/Calib/ideal_out_xb_uniform_bit_norm.npy',\n",
    "                        '../data/Calib/ideal_out_xb_uniform_mid_g.npy']\n",
    "    out_I_path = ['../data/Calib/xb_out_xb_uniform.npy',\n",
    "                  '../data/Calib/xb_out_xb_uniform_bit_norm.npy',\n",
    "                  '../data/Calib/xb_out_xb_uniform_mid_g.npy']\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA is available\")\n",
    "    else:\n",
    "        print(\"CUDA is not available\")\n",
    "    batch_size = 32\n",
    "    seed = 42\n",
    "    epochs = 50\n",
    "    lr = 1e-4\n",
    "    lrf = 0.01\n",
    "    reg_lambda = 0.6\n",
    "    out_type = 'mse'  # mse or cls\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    tb_writer = SummaryWriter(\"../runs/\")\n",
    "\n",
    "    print(\"MNIST dataset generating...\")\n",
    "    dataset = XB_dataset_npy(out_I_paths=out_I_path,\n",
    "                             ideal_out_I_paths=ideal_out_I_path,\n",
    "                             mtx_paths=mtx_path,\n",
    "                             float_mtx_path=float_mtx_path)\n",
    "    dataset_train, dataset_val = random_split(dataset, [int(len(dataset) * 0.8), len(dataset) - int(len(dataset) * 0.8)])\n",
    "\n",
    "    sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "    sampler_val = torch.utils.data.SequentialSampler(dataset_val)\n",
    "\n",
    "    batch_sampler_train = torch.utils.data.BatchSampler(sampler_train, batch_size, drop_last=True)\n",
    "    batch_sampler_val = torch.utils.data.BatchSampler(sampler_val, batch_size, drop_last=True)\n",
    "\n",
    "    print(\"MNIST dataloader generating...\")\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])\n",
    "    print('Using %g dataloader workers' % nw)\n",
    "    data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_sampler=batch_sampler_train,\n",
    "                                                    collate_fn=dataset.collate_fn, num_workers=nw)\n",
    "    data_loader_val = torch.utils.data.DataLoader(dataset_val, batch_sampler=batch_sampler_val,\n",
    "                                                  collate_fn=dataset.collate_fn, num_workers=nw)\n",
    "\n",
    "    print(\"Model generating...\")\n",
    "    model = Calib_model(256, out_type)\n",
    "    model.to(device)\n",
    "\n",
    "    tb_writer.add_graph(model, (torch.randn((batch_size, 2, 16, 32),\n",
    "                                           device=device, dtype=torch.float),\n",
    "                                torch.randn((batch_size, 32),\n",
    "                                            device=device, dtype=torch.float)),\n",
    "                        use_strict_trace=False)\n",
    "\n",
    "    start_epoch = 0\n",
    "    params_to_optimize = []\n",
    "    n_parameters, layers = 0, 0\n",
    "    for p in model.parameters():\n",
    "        n_parameters += p.numel()\n",
    "        layers += 1\n",
    "        if p.requires_grad:\n",
    "            params_to_optimize.append(p)\n",
    "    print('number of params:', n_parameters)\n",
    "    print('Model Summary: %g layers, %g parameters' % (layers, n_parameters))\n",
    "    optimizer = torch.optim.Adam(params_to_optimize, lr=lr)\n",
    "    lf = lambda x: ((1 + math.cos(x * math.pi / epochs)) / 2) * (1 - lrf) + lrf\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lf)\n",
    "    scheduler.last_epoch = start_epoch\n",
    "\n",
    "    # criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    print(\"Start training...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + start_epoch):\n",
    "        train_loss_dict, step_acc = train_one_epoch(model=model, data_loader=data_loader_train,\n",
    "                                                    optimizer=optimizer, device=device, epoch=epoch,\n",
    "                                                    max_norm=0.1, out_type=out_type)\n",
    "        print(str(step_acc))\n",
    "        scheduler.step()\n",
    "\n",
    "        test_loss_dict, step_acc = evaluation(model=model, data_loader=data_loader_val,\n",
    "                                              device=device, epoch=epoch, out_type=out_type)\n",
    "        print(str(step_acc))\n",
    "\n",
    "        items = {\n",
    "            **{f'train_{k}': v for k, v in train_loss_dict.items()},\n",
    "            **{f'test_{k}': v for k, v in test_loss_dict.items()},\n",
    "        }\n",
    "        for k, v in items.items():\n",
    "            tb_writer.add_scalar(k, v, epoch)\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "    # save model\n",
    "    digits = len(str(epochs))\n",
    "    torch.save({\"epoch\": epochs,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"scheduler\": scheduler.state_dict(),\n",
    "               },\n",
    "                '../weights/model_{}.pth'.format(str(epochs).zfill(digits)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "AhyMxNAvtnLn",
    "outputId": "9fa8a71e-bbab-4ab4-dce5-0045b857db29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "MNIST dataset generating...\n",
      "MNIST dataloader generating...\n",
      "Using 8 dataloader workers\n",
      "Model generating...\n",
      "number of params: 435008\n",
      "Model Summary: 17 layers, 435008 parameters\n",
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mamiyKzLvaZ9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
